# ğŸš€ **End-to-End ML Pipeline for Real-Time Material Classification**  
### _(Scrap Simulation Challenge â€” Internship Assignment)_

This project simulates a **real-time classification system** for scrap materials using a **Convolutional Neural Network (CNN)**.  
The goal is to detect and classify waste types (_plastic_, _paper_, _metal_, etc.) from images and simulate a **conveyor-belt-like sorting loop**.

---

## ğŸ“Š **Dataset Used & Why**

- **Dataset**: [TrashNet](https://github.com/garythung/trashnet)  
- **Classes**: `'cardboard'`, `'glass'`, `'metal'`, `'paper'`, `'plastic'`, `'trash'`

**Why TrashNet?**
-  Publicly available
-  Balanced class distribution with labeled images
-  Includes common household waste types relevant to real-world sorting systems

---

## ğŸ§  **Architecture & Training Process**

- **Model**: *Pretrained ResNet18* (Transfer Learning)
- **Modification**: Final layer adapted to predict **6 classes**
- **Input Size**: `224 x 224`
- **Transforms**: Resize, Normalize, Augment (*Random Flip*, *Rotate*, *ColorJitter*)
- **Loss Function**: `CrossEntropyLoss`
- **Epochs**: `5`
- **Batch Size**: `32`

**ğŸ§ª Metrics Used**:
- Accuracy  
- Precision  
- Recall  
- Classification Report

ğŸ“Œ The best model is saved as **`best_model.pt`** whenever validation accuracy improves.

---

## ğŸš€ **Deployment Decisions**

- Converted model to **TorchScript** (`model_scripted.pt`) for lightweight deployment
- Enables **fast inference** without full PyTorch
- Supports **single-image CLI inference** using `inference.py`
- Simulates **real-time classification** using `simulation_loop.py`, processing images one at a time and logging results

---

## ğŸ“ **Folder Structure**
  <pre> 
    End-to-End ML Pipeline for Real-Time Material Classification/
      â”œâ”€â”€ data/
      â”‚   â”œâ”€â”€ cardboard/
      â”‚   â”œâ”€â”€ glass/
      â”‚   â”œâ”€â”€ metal/
      â”‚   â”œâ”€â”€ plastic/
      â”‚   â”œâ”€â”€ paper/
      â”‚   â”œâ”€â”€ trash/
      â”‚   â””â”€â”€ conveyor_simulation/   # Input frames for simulation
      â”œâ”€â”€ models/
      â”‚   â”œâ”€â”€ best_model.pt          # Trained PyTorch model
      â”‚   â””â”€â”€ model_scripted.pt      # TorchScript model for deployment
      â”œâ”€â”€ results/
      â”‚   â””â”€â”€ predictions.csv        # Output logs from simulation
      â”œâ”€â”€ src/
      â”‚   â”œâ”€â”€ data_preparation.py    # Dataset cleaning & preparation
      â”‚   â”œâ”€â”€ train_model.py         # ResNet18 training script
      â”‚   â”œâ”€â”€ inference.py           # Single image inference
      â”‚   â””â”€â”€ simulation_loop.py     # Conveyor belt simulation loop
      â”œâ”€â”€ README.md
      â””â”€â”€ performance_report.pptx    # Performance summary and visuals

     </pre>

---

## ğŸš€ **Deployment Decisions**
ğŸ”¹ Step 1: Create a virtual enviornmnet and download the following packages    
    > Run python -m venv venv  
    > Run .\venv\Scripts\activate  
    > Run pip install torch torchvision Pillow scikit-learn to download the packages given below  
    `torch`, `torchvision`, `scikit-learn`, `Pillow`  
ğŸ”¹ Step 2: Cleaning & Loading the Dataset
    > First Relocate to src folder using cd .\src\  
    > Run python data_preparation.py to clean the dataset.  
    > After cleaning & loading the dataset, the next step is to train the model.  
ğŸ”¹ Step 3: Train the Model
    > To train the model using Resnet18, use the command below.  
    > Run python train_model.py  
    > After training the model now it's time to Convert your model to TorchScript and create a lightweight inference script.  
ğŸ”¹ Step 4: Convert Model to TorchScript & Run Inference
    > To execute this following step, use the command below.  
    > Run python inference.py ../data/conveyor_simulation/glass2.jpg for Single Image Inference.  
    > If you want to use other image you can run this command according to file directory - python inference.py ../data/conveyor_simulation/the_image_you_want_to_select.jpg  
    > After this step, now it's time to build a dummy conveyor simulation.  
Example single image inference
python inference.py ../data/conveyor_simulation/glass2.jpg

Use your own image
python inference.py ../data/conveyor_simulation/<image_name>.jpg
ğŸ”¹ Step 5: Simulate Conveyor Belt Sorting
    > For each frame: Classify, Log output to console + store in a result CSV, Print confidence threshold flag if low.  
    > To execute this, Run simulation_loop.py  
Simulates real-time classification â€” for each image:

Classifies the image

Logs result to console & saves to CSV

Flags low-confidence predictions (< 0.6)

ğŸ“ Sample Output
cardboard1.jpg   â†’  cardboard (0.9691)  
cardboard10.jpg  â†’  cardboard (0.7219)  
cardboard2.jpg   â†’  cardboard (0.5978) âš ï¸ LOW CONFIDENCE  
glass1.jpg       â†’  metal (0.4636) âš ï¸ LOW CONFIDENCE  
glass10.jpg      â†’  glass (0.5032) âš ï¸ LOW CONFIDENCE  

ğŸ“ Results saved in: results/predictions.csv  
âš ï¸ Images with confidence < 0.6 are automatically flagged.
